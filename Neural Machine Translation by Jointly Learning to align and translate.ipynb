{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87618ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4018ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             English  \\\n",
      "0  This weeks 2023 Spring Meetings of the World B...   \n",
      "1  However many communities face social environme...   \n",
      "2  How can policymakers promote the conditions th...   \n",
      "3  In this episode of Voices in Development Kevin...   \n",
      "4  Donovan has used macro and microeconomic model...   \n",
      "\n",
      "                                             Spanish  \n",
      "0  Las Reuniones de Primavera de 2023 del Grupo d...  \n",
      "1  Sin embargo muchas comunidades enfrentan barre...  \n",
      "2  Â¿CÃ³mo pueden los formuladores de polÃ­ticas ...  \n",
      "3  En este episodio de Voices in Development Kevi...  \n",
      "4  Donovan ha utilizado modelos macro y microecon...  \n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "df = pd.read_csv (r\"data.csv\", on_bad_lines='skip', encoding= 'unicode_escape')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c2f72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f3956f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882bf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_english = spacy.load('en_core_web_sm')\n",
    "spacy_spanish = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8ae413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['English_tokens'] = df['English'].apply(lambda x: spacy_english(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(token):\n",
    "    return [lm.lemma_ for lm in token]\n",
    "\n",
    "df['Eng_lemmats'] = df['English_tokens'].apply( lemmatizer )\n",
    "df['Eng_lemmats'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8358aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c749693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_word (text):\n",
    "    #print (text)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    #tokens = spacy_english.tokenizer(text)\n",
    "    #print (tokens)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "    \n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    #print (words)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words\n",
    "    #print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7947692d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [weeks, spring, meetings, world, bank, group, ...\n",
       "1    [however, many, communities, face, social, env...\n",
       "2    [policymakers, promote, conditions, overcome, ...\n",
       "3    [episode, voices, development, kevin, donovan,...\n",
       "4    [donovan, used, macro, microeconomic, models, ...\n",
       "Name: cleaned_english, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_english'] = df['English'].apply( clean_word )\n",
    "df['cleaned_english'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf0c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))\n",
    "punctuation = set(string.punctuation)\n",
    "def clean_word_spanish (text):\n",
    "\n",
    "    # Tokenize the text\n",
    "    doc = spacy_spanish.tokenizer(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # Clean the text\n",
    "\n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.lower() not in stop_words and token not in punctuation:\n",
    "            clean_tokens.append(token)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb73dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [las, reuniones, de, primavera, de, del, grupo...\n",
       "1    [sin, embargo, muchas, comunidades, enfrentan,...\n",
       "2    [pueden, los, formuladores, de, promover, las,...\n",
       "3    [en, este, episodio, de, voices, development, ...\n",
       "4    [donovan, ha, utilizado, modelos, macro, para,...\n",
       "Name: cleaned_spanish, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_spanish'] = df['Spanish'].apply( clean_word )\n",
    "df['cleaned_spanish'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f8d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_english = df[\"cleaned_english\"].tolist()\n",
    "all_words_spanish = df[\"cleaned_spanish\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93438a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_vocabulary_count (my_corpus):\n",
    "    my_list = []\n",
    "    total_words = []\n",
    "    for c, row in enumerate (my_corpus):\n",
    "       #print (\"row : \\n \", row)\n",
    "       for w in row:\n",
    "            total_words.append (w)\n",
    "            if w not in my_list:\n",
    "                my_list.append (w)\n",
    "    #print (my_list)\n",
    "    counts = Counter(total_words)\n",
    "    return my_list, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09731e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weeks', 'spring', 'meetings', 'world', 'bank', 'group', 'imf', 'focus', 'development', 'new', 'era', 'important', 'reminder', 'systemic', 'change', 'happen', 'overnight', 'strong', 'economic', 'requires', 'adequate', 'infrastructure', 'individual', 'access', 'markets', 'opportunities', 'however', 'many', 'communities', 'face', 'social', 'environmental', 'barriers', 'hobble', 'harsh', 'landscapes', 'remote', 'settings', 'constrain', 'crises', 'pandemic', 'food', 'insecurity', 'climate', 'set', 'back', 'hardearned', 'gains', 'policymakers', 'promote', 'conditions', 'overcome', 'constraints', 'take', 'advantage', 'role', 'transforming', 'labor', 'catalyzing', 'episode', 'voices', 'kevin', 'donovan', 'assistant', 'professor', 'economics', 'global', 'affairs', 'egc', 'affiliate', 'discusses', 'diverse', 'body', 'recent', 'work', 'unpacking', 'tools', 'needed', 'countries', 'make', 'marketdriven', 'transitions', 'overlapping', 'used', 'macro', 'microeconomic', 'models', 'explore', 'knowledge', 'transfers', 'among', 'kenyan', 'microenterprise', 'owners', 'implications', 'shifting', 'market', 'dynamics', 'policy', 'ability', 'last', 'mile', 'pedestrian', 'bridges', 'connect', 'rural', 'villages', 'cities', 'low', 'middleincome', 'lmics', 'collaboration', 'prosperity', 'insights', 'bridge', 'built', 'nicaragua', 'concluded', 'gave', 'crucial', 'better', 'paid', 'jobs', 'also', 'spillover', 'benefits', 'connecting', 'people', 'schools', 'hospitals', 'results', 'suggest', 'big', 'type', 'lots', 'margins', 'get', 'affected', 'intervention', 'gets', 'true', 'great', 'selling', 'crops', 'getting', 'higher', 'paying', 'youre', 'turns', 'pretty', 'cost', 'effective', 'way', 'help', 'areas', 'recognizing', 'improving', 'one', 'component', 'journey', 'need', 'harness', 'sustainable', 'growth', 'large', 'datasets', 'regular', 'turnover', 'may', 'indicative', 'healthy', 'economy', 'podcast', 'explores', 'similar', 'poorer', 'reveal', 'insecurities', 'present', 'early', 'stages', 'job', 'ladder', 'received', 'phd', 'arizona', 'state', 'university', 'since', 'conducted', 'extensive', 'research', 'firm', 'previously', 'worked', 'department', 'notre', 'dame', 'published', 'quarterly', 'journal', 'review', 'studies', 'econometrica', 'april', 'chagas', 'disease', 'day', 'discovery', 'brazilian', 'researcher', 'carlos', 'ribeiro', 'justiniano', 'epidemic', 'spread', 'latin', 'america', 'united', 'states', 'untreated', 'patients', 'risk', 'disorders', 'including', 'arrythmias', 'dilated', 'cardiomyopathy', 'heart', 'failure', 'raising', 'awareness', 'healthcare', 'providers', 'priority', 'bernardo', 'lombo', 'md', 'clinical', 'medicine', 'yale', 'school', 'expert', 'erica', 'j', 'rayack', 'jointdegree', 'msnmph', 'student', 'studying', 'epidemiology', 'microbial', 'diseases', 'family', 'public', 'health', 'nursing', 'created', 'anonymous', 'provider', 'survey', 'assess', 'spoke', 'screening', 'medical', 'services', 'first', 'learned', 'costa', 'rican', 'physician', 'taught', 'much', 'study', 'abroad', 'program', 'later', 'burden', 'independent', 'class', 'struck', 'neglected', 'especially', 'estimated', 'anywhere', 'infants', 'us', 'born', 'infection', 'year', 'spreads', 'insect', 'vector', 'thought', 'infections', 'caused', 'biting', 'person', 'taking', 'blood', 'meal', 'defecating', 'parasiteinfested', 'feces', 'near', 'bite', 'area', 'regions', 'oral', 'ingestion', 'protozoan', 'parasites', 'seen', 'primary', 'source', 'infectionâ', 'rather', 'blame', 'would', 'due', 'something', 'like', 'fresh', 'fruit', 'juice', 'contaminated', 'infected', 'bug', 'hypothesized', 'main', 'route', 'autochthonous', 'well', 'far', 'understand', 'number', 'congenitallyinfected', 'phenylketonuria', 'typically', 'diagnosed', 'newborn', 'importance', 'birthing', 'parent', 'patient', 'contemplating', 'pregnancy', 'highlighted', 'reduced', 'ofâ', 'congenital', 'transmissionï', 'treated', 'prior', 'greater', 'cure', 'rate', 'within', 'life', 'high', 'presents', 'care', 'critical', 'opportunity', 'prevent', 'generation', 'next', 'factor', 'think', 'triatomines', 'already', 'found', 'almost', 'habitat', 'loss', 'changes', 'insects', 'move', 'relation', 'humans', 'rates', 'reservoir', 'species', 'become', 'accessible', 'even', 'transmit', 'pathogens', 'lot', 'vectors', 'mosquitos', 'course', 'cause', 'triatomine', 'bugs', 'researchers', 'tackling', 'kinds', 'questions', 'regard', 'use', 'attention', 'continues', 'altered', 'human', 'activities', 'whether', 'pop', 'belong', 'subspecies', 'capable', 'carrying', 'spreading', 'parasite', 'remains', 'certainly', 'concern', 'lived', 'highly', 'endemic', 'region', 'major', 'prevalence', 'include', 'bolivia', 'venezuela', 'brazil', 'argentina', 'extend', 'throughout', 'americas', 'southwest', 'statesâ', 'acquiring', 'often', 'associated', 'living', 'parts', 'though', 'exceptions', 'rule', 'less', 'likely', 'come', 'contact', 'parasitecarrying', 'said', 'populations', 'static', 'never', 'known', 'always', 'staying', 'place', 'emigrate', 'travel', 'someone', 'country', 'programs', 'relatively', 'robust', 'consider', 'atrisk', 'perform', 'test', 'symptomatic', 'developedâ', 'thankfully', 'several', 'groups', 'working', 'situation', 'continued', 'neglect', 'hearts', 'east', 'boston', 'lasocha', 'american', 'society', 'dc', 'center', 'excellence', 'los', 'angeles', 'professionals', 'clinicians', 'texas', 'hope', 'various', 'specialties', 'together', 'heavily', 'equity', 'issue', 'best', 'resources', 'students', 'hoping', 'learn', 'sessions', 'put', 'ut', 'san', 'antonio', 'project', 'echo', 'extension', 'community', 'outcomes', 'past', 'available', 'website', 'cmes', 'register', 'attend', 'live', 'complexities', 'encouraging', 'frequent', 'testing', 'support', 'diagnosis', 'treatment', 'furthermore', 'evidence', 'bolster', 'challenge', 'current', 'recommendations', 'instance', 'recommendation', 'screen', 'significant', 'amount', 'time', 'age', 'might', 'little', 'benefit', 'specify', 'specificity', 'two', 'different', 'assays', 'diagnostic', 'following', 'pan', 'organization', 'centers', 'control', 'prevention', 'cdc', 'guidelinesï', 'three', 'elisas', 'rapid', 'immunochromatographic', 'assay', 'varying', 'accessibility', 'positives', 'required', 'confirmed', 'case', 'discordance', 'third', 'distinct', 'performed', 'commercial', 'labs', 'carry', 'confirmatory', 'must', 'done', 'infectious', 'authors', 'experts', 'paired', 'asymptomatic', 'targeted', 'toward', 'pregnant', 'system', 'associate', 'provide', 'fertile', 'ground', 'developing', 'ideally', 'outreach', 'interdisciplinary', 'networks', 'things', 'appropriate', 'plan', 'screened', 'positive', 'relevant', 'cardiologists', 'order', 'cruzy', 'serologic', 'epidemiological', 'factors', 'presence', 'ecg', 'right', 'ventricular', 'branch', 'block', 'left', 'anterior', 'fascicular', 'degree', 'av', 'premature', 'contractions', 'tachycardia', 'atrial', 'fibrillation', 'month', 'connecticut', 'history', 'national', 'held', 'regional', 'contests', 'march', 'library', 'staff', 'members', 'hand', 'southern', 'assist', 'judging', 'participated', 'wilbur', 'cross', 'worthington', 'hooker', 'engineeringscience', 'magnet', 'home', 'contest', 'designed', 'encourage', 'middle', 'highschool', 'engage', 'collegelevel', 'historical', 'interpretation', 'creative', 'expression', 'response', 'annual', 'theme', 'choose', 'topics', 'interest', 'yearlong', 'share', 'findings', 'presentations', 'invites', 'museum', 'teachers', 'scholars', 'exploration', 'chosen', 'serving', 'ask', 'offer', 'feedback', 'encouragement', 'direction', 'young', 'historians', 'six', 'librarians', 'volunteered', 'serve', 'judges', 'part', 'event', 'lerner', 'melissa', 'allstaff', 'email', 'encouraged', 'enjoyed', 'interviewing', 'engagement', 'sources', 'willingness', 'voice', 'frustrations', 'difficulties', 'encountered', 'researching', 'creating', 'exhibit', 'expressed', 'deep', 'curiosity', 'ended', 'teaching', 'kirkpatrick', 'team', 'leader', 'teams', 'evaluating', 'junior', 'exhibits', 'fourth', 'projects', 'nerd', 'try', 'meaningful', 'difference', 'perspectives', 'jam', 'thomas', 'thurston', 'director', 'education', 'gilder', 'lehrman', 'represented', 'judge', 'years', 'involved', 'organizing', 'competition', 'real', 'sense', 'goes', 'simply', 'statewide', 'seeing', 'excitement', 'families', 'made', 'worthwhile', 'endeavor', 'assigned', 'individualstudent', 'studentgroup', 'submissions', 'speak', 'subject', 'process', 'argument', 'collaborate', 'evaluate', 'written', 'proposals', 'final', 'detailed', 'rubric', 'constructive', 'comments', 'signed', 'saw', 'otherwise', 'younger', 'dougherty', 'particularly', 'crafted', 'engaging', 'challenging', 'subjects', 'receive', 'copies', 'suggestions', 'qualify', 'enter', 'chance', 'refine', 'based', 'resubmit', 'thousands', 'exhibitions', 'papers', 'documentaries', 'websites', 'performances', 'around', 'places', 'ideas', 'concept', 'broad', 'enough', 'encompass', 'local', 'variety', 'ranged', 'manhattan', 'heliocentric', 'theory', 'smallpox', 'vaccine', 'shinkansen', 'bullet', 'train', 'maya', 'lin', 'freedom', 'riders', 'richard', 'nixon', 'beatles', 'tremendous', 'joy', 'dreary', 'saturday', 'see', 'hard', 'unique', 'barton', 'impressive', 'polish', 'verve', 'along', 'inspiring', 'range', 'librarian', 'proud', 'closing', 'ceremony', 'congresswoman', 'rosa', 'delauro', 'joe', 'bertolino', 'president', 'awarded', 'second', 'thirdplace', 'prizes', 'senior', 'divisions', 'topplace', 'winners', 'competitions', 'compete', 'central', 'roberta', 'trip', 'sarah', 'headed', 'win', 'go', 'maryland', 'college', 'park', 'june', 'occasionally', 'remark', 'interested', 'days', 'notion', 'troubles', 'recommend', 'renowned', 'clark', 'ladies', 'gospel', 'described', 'title', 'sterling', 'add', 'growing', 'collection', 'taped', 'interviews', 'prominent', 'figures', 'music', 'sisters', 'pioneering', 'fusion', 'musical', 'styles', 'produced', 'albums', 'date', 'individually', 'grammy', 'awards', 'ambre', 'dromgoole', 'mar', 'candidate', 'african', 'religious', 'interviewed', 'four', 'women', 'jacky', 'chisholm', 'elbernita', 'dorinda', 'clarkcole', 'karen', 'sheard', 'grew', 'singer', 'church', 'musician', 'nashville', 'tennessee', 'daughters', 'composer', 'choral', 'dr', 'mattie', 'moss', 'figure', 'nationwide', 'founder', 'conservatory', 'detroit', 'hometown', 'served', 'god', 'international', 'trained', 'performance', 'turn', 'passed', 'love', 'children', 'business', 'mothers', 'aunts', 'going', 'legacy', 'angle', 'ends', 'advance', 'interview', 'session', 'feels', 'taken', 'able', 'instill', 'memory', 'mother', 'forecasting', 'future', 'generations', 'oham', 'institute', 'sacred', 'black', 'launched', 'braxton', 'shelley', 'videotaped', 'comprises', 'recorded', 'composers', 'musicians', 'streamed', 'online', 'using', 'aviary', 'platform', 'information', 'view', 'tables', 'contents', 'request', 'transcripts', 'select', 'tab', 'guide', 'week', 'announced', 'recipients', 'windham', 'campbell', 'prize', 'recognition', 'exceptional', 'literary', 'achievement', 'established', 'gift', 'donald', 'sandy', 'writers', 'eight', 'windhamcampbell', 'personal', 'complex', 'issues', 'sexuality', 'politics', 'culture', 'reading', 'excited', 'ways', 'michael', 'kelleher', 'wait', 'presented', 'fall', 'festival', 'marking', 'increase', 'previous', 'administered', 'beinecke', 'rare', 'book', 'manuscript', 'generous', 'prestigious', 'conferred', 'annually', 'english', 'stage', 'careers', 'ninetyone', 'representing', 'across', 'globe', 'nominated', 'confidentially', 'judged', 'anonymously', 'know', 'considered', 'contacts', 'decision', 'understatement', 'shocked', 'upon', 'learning', 'percival', 'everett', 'author', 'books', 'fiction', 'poetry', 'novel', 'finalist', 'pulitzer', 'fellow', 'recipient', 'ling', 'authored', 'short', 'story', 'montage', 'named', 'york', 'times', 'notable', 'londonbased', 'writer', 'historian', 'susan', 'examines', 'concealed', 'histories', 'documentary', 'destroyed', 'classified', 'redacted', 'malice', 'cia', 'covert', 'recolonization', 'africa', 'moves', 'congo', 'ghana', 'late', 'shed', 'light', 'deliberate', 'violation', 'democracy', 'newly', 'unexpected', 'validation', 'struggle', 'interrogate', 'search', 'truth', 'williams', 'deeply', 'grateful', 'inspiration', 'push', 'forward', 'renewed', 'strength', 'resolve', 'darran', 'anderson', 'essayist', 'journalist', 'memoirist', 'writes', 'intersections', 'urbanism', 'technology', 'tells', 'workingclass', 'catholic', 'childhood', 'derry', 'northern', 'ireland', 'height', 'dramatist', 'dominique', 'works', 'critically', 'acclaimed', 'threeplay', 'cycle', 'draws', 'rich', 'literature', 'activism', 'create', 'unflinching', 'wildly', 'entertaining', 'dramatic', 'experiences', 'morisseau', 'tony', 'award', 'temptations', 'macarthur', 'fellowship', 'beyond', 'joyous', 'matter', 'im', 'continue', 'artist', 'telling', 'stories', 'vital', 'mission', 'pathway', 'creativity', 'passion', 'thrive', 'thrilling', 'old', 'playwright', 'jasmine', 'leejones', 'youngestever', 'burst', 'theater', 'scene', 'debut', 'play', 'methods', 'killing', 'kylie', 'jenner', 'follows', 'cleo', 'selfproclaimed', 'twitter', 'activist', 'friend', 'kara', 'negotiate', 'increasingly', 'entangled', 'offline', 'identities', 'sophomore', 'racial', 'britain', 'century', 'poet', 'alexis', 'pauline', 'gumbs', 'critic', 'scholar', 'educator', 'uses', 'hybrid', 'forms', 'reenvision', 'narratives', 'intellectualimaginative', 'prosepoetry', 'finding', 'archive', 'scenes', 'feminist', 'fugitivity', 'southcentral', 'alaska', 'dg', 'nanouk', 'opens', 'readers', 'web', 'ecology', 'myth', 'whale', 'latest', 'snow', 'former', 'laureate', 'harjo', 'surprising', 'prophetic', 'ceremonial', 'disruptive', 'thousand', 'marmots', 'running', 'tundra', 'okpik', 'partner', 'couple', 'discussed', 'highlight', 'financial', 'concerns', 'died', 'unexpectedly', 'took', 'responsibility', 'making', 'shared', 'dream', 'reality', 'theodore', 'kim', 'computer', 'science', 'engineering', 'applied', 'coleader', 'graphics', 'scientist', 'pixar', 'twotime', 'academy', 'winner', 'counter', 'bias', 'animation', 'peter', 'salovey', 'graduate', 'lowe', 'phdï', 'joined', 'lowincome', 'unmarried', 'orleans', 'hurricane', 'katrina', 'collective', 'events', 'impact', 'disparities', 'psychologist', 'behavioral', 'sciences', 'psychiatry', 'surveyed', 'noting', 'negative', 'lives', 'overall', 'resilience', 'setback', 'earning', 'degrees', 'stable', 'housing', 'successfully', 'despite', 'trauma', 'hit', 'became', 'clear', 'affect', 'subpopulations', 'equally', 'characteristics', 'experiencing', 'racism', 'income', 'single', 'increased', 'covid', 'severe', 'cases', 'suffering', 'myriad', 'impacts', 'noted', 'vulnerable', 'experienced', 'another', 'approximately', 'publishing', 'paper', 'february', 'lead', 'meghan', 'zacher', 'population', 'brown', 'ethan', 'raker', 'sociology', 'british', 'columbia', 'compared', 'mental', 'surprised', 'nearly', 'percent', 'survivors', 'posttraumatic', 'stress', 'symptoms', 'exact', 'percentage', 'half', 'respondents', 'psychological', 'distress', 'onethird', 'postkatrina', 'worse', 'worst', 'disasters', 'speaks', 'differences', 'experience', 'shorter', 'period', 'geographically', 'constrained', 'says', 'meaning', 'rest', 'could', 'channel', 'gulf', 'coast', 'everyone', 'widespread', 'illness', 'death', 'lasted', 'longer', 'graver', 'duration', 'combined', 'led', 'focused', 'specific', 'subpopulation', 'offers', 'general', 'showed', 'longterm', 'forget', 'moving', 'deaths', 'mean', 'arent', 'continuing', 'adversity', 'traumas', 'habituate', 'wearandtear', 'folks', 'cope', 'grow', 'key', 'emerge', 'tragic', 'extreme', 'weather', 'outbreaks', 'mass', 'shootings', 'fatal', 'fires', 'multiplevictim', 'auto', 'accidents', 'amend', 'definition', 'statistical', 'manual', 'authoritative', 'handbook', 'account', 'struggles', 'strain', 'instability', 'discrimination', 'believe', 'easier', 'traumarelated', 'coresearchers', 'sift', 'expect', 'publish', 'followup', 'bob', 'atkinson', 'firstgeneration', 'air', 'force', 'veteran', 'earned', 'bronze', 'stars', 'selected', 'truman', 'eli', 'whitney', 'helps', 'nontraditional', 'earn', 'undergraduate', 'scholarship', 'aspiring', 'service', 'leaders', 'provides', 'funding', 'leadership', 'training', 'career', 'counseling', 'special', 'internship', 'government', 'candidates', 'colleges', 'universities', 'basis', 'academic', 'success', 'accomplishments', 'potential', 'confidence', 'trumans', 'meet', 'challenges', 'terry', 'babcocklumish', 'executive', 'secretary', 'reflect', 'innovative', 'purposeful', 'patriotic', 'problemsolvers', 'shying', 'away', 'trumbull', 'originally', 'janesville', 'minnesota', 'graduating', 'enlisted', 'usaf', 'undertook', 'warfare', 'member', 'directly', 'ranger', 'regimental', 'reconnaissance', 'company', 'combat', 'deployments', 'afghanistan', 'iraq', 'twice', 'star', 'medal', 'heroic', 'meritorious', 'wants', 'shape', 'drug', 'medicationassisted', 'eliminating', 'domestic', 'opioid', 'intern', 'bureau', 'narcotics', 'law', 'enforcement', 'focusing', 'illicit', 'supply', 'reduction', 'plans', 'pursue', 'bobby', 'glad', 'foundation', 'record', 'commitment', 'jill', 'carrera', 'office', 'fellowships', 'representative', 'advising', 'introduces', 'dedicated', 'sector', 'dedication', 'congress', 'memorial', 'harry', 'monument', 'join', 'security', 'advisor', 'jake', 'sullivan', 'jd', 'supreme', 'court', 'justice', 'neil', 'gorsuch', 'white', 'house', 'rice', 'fair', 'fight', 'stacey', 'abrams', 'toxic', 'materials', 'dod', 'revealed', 'specifics', 'regarding', 'contamination', 'extent', 'exposure', 'deployed', 'servicemembers', 'matt', 'erpelding', 'sff', 'got', 'sick', 'nausea', 'headaches', 'rashes', 'still', 'serious', 'illnesses', 'sen', 'blumenthal', 'introduced', 'veterans', 'act', 'substances', 'exposed', 'blumental', 'withholding', 'imperils', 'unacceptable', 'obstacle', 'receiving', 'stake', 'wrong', 'swiftly', 'corrected', 'litigation', 'filed', 'today', 'result', 'numerous', 'foia', 'attempts', 'obtain', 'toxins', 'documented', 'expedite', 'johns', 'hopkins', 'data', 'diagnosing', 'linked', 'stronghold', 'tirelessly', 'anyone', 'spent', 'quickly', 'deserve', 'alison', 'weir', 'cvlc', 'parties', 'suit', 'unfathomable', 'defense', 'obstruct', 'impacting', 'legal', 'unfortunately', 'timeandtime', 'beside', 'ensure', 'deserved', 'submitted', 'requests', 'responsive', 'records', 'according', 'nothing', 'disheartening', 'abandoned', 'derek', 'nelson', 'army', 'clinic', 'dying', 'lawsuit', 'step', 'remedying', 'abandonment', 'providing', 'darwall', 'andrew', 'downey', 'orrick', 'philosophy', 'faculty', 'arts', 'philosophers', 'guggenheim', 'simon', 'olga', 'son', 'john', 'honors', 'individuals', 'pursuit', 'field', 'creation', 'art', 'form', 'grant', 'vary', 'fellows', 'wish']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "english_vocabulary, counts = find_vocabulary_count (all_words_english)\n",
    "print (english_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51be6886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['las', 'reuniones', 'de', 'primavera', 'del', 'grupo', 'banco', 'mundial', 'el', 'fmi', 'esta', 'semana', 'centradas', 'en', 'desarrollo', 'para', 'una', 'nueva', 'son', 'un', 'recordatorio', 'importante', 'que', 'cambio', 'ocurre', 'la', 'noche', 'fuerte', 'requiere', 'infraestructura', 'adecuada', 'acceso', 'individual', 'mercados', 'oportunidades', 'sin', 'embargo', 'muchas', 'comunidades', 'enfrentan', 'barreras', 'sociales', 'ambientales', 'obstaculizan', 'los', 'paisajes', 'hostiles', 'entornos', 'remotos', 'pueden', 'restringir', 'crisis', 'como', 'pandemia', 'inseguridad', 'alimentaria', 'retrasar', 'avances', 'obtenidos', 'con', 'tanto', 'esfuerzo', 'formuladores', 'promover', 'condiciones', 'superen', 'estas', 'limitaciones', 'aprovechar', 'papel', 'laborales', 'este', 'episodio', 'voices', 'development', 'kevin', 'donovan', 'profesor', 'asistente', 'asuntos', 'globales', 'afiliado', 'egc', 'analiza', 'su', 'diverso', 'cuerpo', 'trabajo', 'reciente', 'revela', 'herramientas', 'necesarias', 'realicen', 'transiciones', 'impulsadas', 'por', 'mercado', 'era', 'superpuestas', 'ha', 'utilizado', 'modelos', 'macro', 'explorar', 'transferencias', 'conocimiento', 'entre', 'propietarios', 'microempresas', 'kenia', 'implicaciones', 'cambiar', 'laboral', 'capacidad', 'ãºltima', 'milla', 'puentes', 'peatonales', 'conectar', 'pueblos', 'rurales', 'ciudades', 'ingresos', 'bajos', 'medianos', 'lmic', 'bridges', 'prosperity', 'ideas', 'sobre', 'puente', 'construido', 'nicaragua', 'concluyeron', 'solo', 'les', 'dio', 'aldeas', 'crucial', 'trabajos', 'mejor', 'pagados', 'sino', 'tuvo', 'beneficios', 'indirectos', 'al', 'personas', 'escuelas', 'hospitales', 'nuestros', 'resultados', 'sugieren', 'hay', 'grandes', 'tipo', 'muchos', 'se', 'ven', 'afectados', 'misma', 'mismo', 'construye', 'es', 'cierto', 'obtienes', 'lo', 'cual', 'excelente', 'vender', 'tus', 'cultivos', 'obtener', 'pero', 'conectando', 'resulta', 'ser', 'forma', 'bastante', 'rentable', 'ayudar', 'zonas', 'reconocer', 'mejorar', 'componente', 'viaje', 'deben', 'emprender', 'crecimiento', 'sostenible', 'conjuntos', 'datos', 'si', 'bien', 'algunos', 'regular', 'puede', 'indicativa', 'saludable', 'podcast', 'explora', 'similares', 'pobres', 'revelar', 'inseguridades', 'presentes', 'primeras', 'etapas', 'escala', 'doctorado', 'universidad', 'estatal', 'arizona', 'desde', 'entonces', 'realizado', 'extensa', 'empresarial', 'anteriormente', 'departamento', 'notre', 'dame', 'sido', 'publicado', 'quarterly', 'journal', 'economics', 'review', 'economic', 'studies', 'econometrica', 'abril', 'enfermedad', 'chagas', 'descubrimiento', 'investigador', 'carlos', 'ribeiro', 'justiniano', 'epidemia', 'extendido', 'latina', 'hasta', 'estados', 'unidos', 'cuando', 'reciben', 'tratamiento', 'pacientes', 'corren', 'riesgo', 'sufrir', 'trastornos', 'incluyen', 'arritmias', 'dilatada', 'insuficiencia', 'prioridad', 'concienciar', 'proveedores', 'bernardo', 'lombo', 'md', 'medicina', 'escuela', 'yale', 'experto', 'erica', 'j', 'rayack', 'estudiante', 'grado', 'conjunto', 'msnmph', 'estudia', 'enfermedades', 'microbianas', 'familiar', 'salud', 'pãºblica', 'encuesta', 'evaluar', 'hablamos', 'ellos', 'servicios', 'primera', 'vez', 'costarricense', 'gran', 'parte', 'mi', 'programa', 'estudios', 'extranjero', 'tarde', 'carga', 'global', 'mientras', 'realizaba', 'independiente', 'clase', 'descuidada', 'especialmente', 'donde', 'estima', 'poco', 'menos', 'tienen', 'ee', 'uu', 'nacen', 'cada', 'propaga', 'insecto', 'vector', 'pensado', 'infecciones', 'causadas', 'pica', 'persona', 'ingiere', 'sangre', 'luego', 'defeca', 'heces', 'infestadas', 'cerca', 'picadura', 'ahora', 'regiones', 'mundo', 'oral', 'protozoarios', 'considera', 'principal', 'fuente', 'lugar', 'culpar', 'debe', 'algo', 'jugo', 'fruta', 'fresca', 'contaminado', 'infectado', 'insectos', 'planteado', 'ruta', 'segãºn', 'tengo', 'entendido', 'esa', 'cantidad', 'infectados', 'similar', 'fenilcetonuria', 'generalmente', 'diagnostica', 'pruebas', 'nacidos', 'importancia', 'padres', 'dan', 'luz', 'contemplan', 'embarazo', 'destaca', 'reducido', 'tratadas', 'antes', 'tasa', 'superior', 'tratados', 'durante', 'primer', 'vida', 'alta', 'presenta', 'oportunidad', 'prevenir', 'siguiente', 'factor', 'pensamos', 'cualquier', 'triatominos', 'ya', 'encontrar', 'casi', 'cambia', 'mueven', 'humanos', 'tasas', 'mordeduras', 'especies', 'reservorio', 'volverse', 'accesibles', 'incluso', 'transmitir', 'tenemos', 'mucha', 'esto', 'vectores', 'mosquitos', 'supuesto', 'causan', 'investigadores', 'abordan', 'preguntas', 'respecto', 'necesitar', 'nuestro', 'clima', 'continãºa', 'siendo', 'alterado', 'actividades', 'humanas', 'queda', 'verse', 'nuevas', 'especie', 'subespecie', 'capaz', 'transportar', 'propagar', 'ciertamente', 'haber', 'vivido', 'altamente', 'prevalencia', 'bolivia', 'venezuela', 'brasil', 'argentina', 'extienden', 'todo', 'continente', 'americano', 'incluido', 'suroeste', 'contraer', 'menudo', 'asocia', 'vivir', 'aunque', 'excepciones', 'regla', 'mucho', 'probable', 'entremos', 'contacto', 'triatomino', 'portador', 'otras', 'dicho', 'poblaciones', 'gente', 'nunca', 'conocida', 'permanecer', 'siempre', 'emigran', 'viajan', 'alguien', 'mudarse', 'programas', 'relativamente', 'ningãºn', 'proveedor', 'le', 'siquiera', 'considerar', 'sus', 'posible', 'otros', 'prueba', 'haya', 'desarrollado', 'afortunadamente', 'varios', 'grupos', 'trabajando', 'abandono', 'continuo', 'strong', 'hearts', 'east', 'boston', 'lasocha', 'sociedad', 'latinoamericana', 'fuera', 'dc', 'centro', 'excelencia', 'profesionales', 'texas', 'esperanza', 'nuestras', 'diversas', 'especialidades', 'unan', 'centren', 'tema', 'equidad', 'uno', 'mejores', 'recursos', 'estudiantes', 'e', 'esperan', 'aprender', 'sesiones', 'organizadas', 'ut', 'health', 'san', 'antonio', 'project', 'echo', 'extension', 'community', 'healthcare', 'outcomes', 'todas', 'anteriores', 'disponibles', 'sitio', 'web', 'cme', 'aquellos', 'registran', 'asisten', 'vivo', 'principales', 'complejidades', 'alentar', 'frecuentes', 'apoyar', 'necesitamos', 'evidencia', 'reforzar', 'desafiar', 'recomendaciones', 'actuales', 'ejemplo', 'han', 'significativa', 'tiempo', 'edad', 'tener', 'beneficio', 'publicadas', 'especifican', 'debido', 'baja', 'especificidad', 'usar', 'dos', 'ensayos', 'diferentes', 'siguiendo', 'pautas', 'panamericana', 'centros', 'control', 'cdc', 'tres', 'elisa', 'ensayo', 'todos', 'diferente', 'accesibilidad', 'requieren', 'positivos', 'confirmado', 'caso', 'discordancia', 'necesario', 'realizar', 'tercera', 'distinta', 'laboratorios', 'comerciales', 'realizarse', 'infectious', 'diseases', 'autores', 'expertos', 'incluidos', 'combinarse', 'sea', 'mayor', 'dirigida', 'embarazadas', 'sistema', 'new', 'asociado', 'brindan', 'terreno', 'desarrollar', 'paciente', 'idealmente', 'alcance', 'comunitario', 'apoyo', 'redes', 'interdisciplinarias', 'igual', 'cosas', 'importantes', 'plan', 'adecuado', 'examinados', 'positivo', 'eso', 'relevantes', 'ordenar', 'cruzy', 'factores', 'presencia', 'ecg', 'bloqueo', 'rama', 'ventricular', 'derecha', 'fascicular', 'anterior', 'izquierdo', 'av', 'ventriculares', 'taquicardia', 'auricular', 'mes', 'pasado', 'historia', 'connecticut', 'afiliados', 'nacional', 'concursos', 'regionales', 'estado', 'marzo', 'miembros', 'personal', 'biblioteca', 'estuvieron', 'sur', 'participaron', 'wilbur', 'cross', 'high', 'school', 'worthington', 'hooker', 'magnet', 'ciencias', 'fueron', 'algunas', 'origen', 'concurso', 'secundaria', 'preparatoria', 'participar', 'creativa', 'nivel', 'universitario', 'respuesta', 'anual', 'eligen', 'temas', 'participan', 'investigaciones', 'comparten', 'hallazgos', 'presentaciones', 'creativas', 'invita', 'museos', 'bibliotecas', 'maestros', 'elegidos', 'sirviendo', 'jueces', 'hacer', 'ofrecer', 'comentarios', 'brindar', 'aliento', 'historiadores', 'seis', 'bibliotecarios', 'ofrecieron', 'fue', 'participando', 'evento', 'dijo', 'lerner', 'correo', 'melissa', 'barton', 'hacerlo', 'entrevistar', 'compromiso', 'fuentes', 'primarias', 'alentador', 'expresar', 'frustraciones', 'dificultades', 'encontraron', 'investigaban', 'creaban', 'expresaron', 'profunda', 'curiosidad', 'nuevo', 'kirkpatrick', 'equipo', 'equipos', 'evaluaron', 'exhibiciones', 'individuales', 'cuarto', 'evaluando', 'proyectos', 'nerd', 'gusta', 'tratar', 'marcar', 'diferencia', 'perspectivas', 'guste', 'thomas', 'thurston', 'director', 'pãºblico', 'gilder', 'lehrman', 'juez', 'organizar', 'competencia', 'regional', 'cabo', 'idea', 'real', 'implica', 'simplemente', 'ver', 'entusiasmo', 'familias', 'hizo', 'valiera', 'pena', 'trabajan', 'revisar', 'asignadas', 'hablan', 'proceso', 'argumento', 'colaboran', 'evalãºan', 'propuestas', 'escritas', 'finales', 'rãºbrica', 'detallada', 'proporciona', 'constructivos', 'escrito', 'porque', 'vi', 'retribuir', 'comunidad', 'contrario', 'relacionarme', 'dougherty', 'trabajar', 'elaboramos', 'involucran', 'muy', 'desafiantes', 'copias', 'beneficiarse', 'sugerencias', 'califiquen', 'refinar', 'instrucciones', 'volver', 'presentarlos', 'miles', 'crearon', 'exposiciones', 'documentales', 'sitios', 'representaciones', 'torno', 'fronteras', 'lugares', 'concepto', 'suficientemente', 'amplio', 'abarcar', 'local', 'variedad', 'iban', 'proyecto', 'manhattan', 'vacuna', 'contra', 'viruela', 'tren', 'bala', 'shinkansen', 'maya', 'lin', 'freedom', 'riders', 'richard', 'nixon', 'beatles', 'tremenda', 'triste', 'arduo', 'voces', 'ãºnicas', 'estos', 'brillo', 'impresionantes', 'junto', 'inspiradora', 'bibliotecario', 'ceremonia', 'clausura', 'congresista', 'rosa', 'delauro', 'joe', 'bertolino', 'presidente', 'otorgaron', 'premios', 'segundo', 'tercer', 'divisiones', 'junior', 'senior', 'ganadores', 'competencias', 'mayo', 'central', 'roberta', 'trip', 'sarah', 'encuentran', 'dirigieron', 'ganen', 'maryland', 'college', 'park', 'junio', 'ocasionalmente', 'interesados', 'te', 'preocupa', 'recomiendo', 'encarecidamente', 'juzgues', 'renombradas', 'clark', 'sisters', 'damas', 'evangelio', 'describe', 'visitaron', 'sterling', 'agregar', 'creciente', 'entrevistas', 'grabadas', 'figuras', 'prominentes', 'mãºsica', 'gospel', 'conocidas', 'pionera', 'estilos', 'musicales', 'producido', 'fecha', 'individualmente', 'ganado', 'grammy', 'ambre', 'dromgoole', 'mar', 'candidata', 'afroamericanos', 'religiosos', 'cuatro', 'mujeres', 'jacky', 'chisholm', 'elbernita', 'twinkie', 'dorinda', 'clarkcole', 'karen', 'sheard', 'propia', 'cantante', 'iglesia', 'nashville', 'tennessee', 'hermanas', 'hijas', 'mãºsico', 'compositor', 'coral', 'dr', 'mattie', 'moss', 'quien', 'figura', 'fundador', 'conservatorio', 'detroit', 'ciudad', 'natal', 'familia', 'presidenta', 'internacional', 'dios', 'cristo', 'dra', 'musical', 'temprana', 'ellas', 'transmitido', 'amor', 'hijos', 'involucrados', 'negocio', 'alguna', 'manera', 'actuado', 'madres', 'voy', 'llegar', 'punto', 'vista', 'legado', 'ambos', 'extremos', 'entrevista', 'parece', 'tenido', 'cuidado', 'poder', 'inculcar', 'recuerdo', 'madre', 'pronostica', 'generaciones', 'futuras', 'history', 'american', 'music', 'oham', 'instituto', 'sagrada', 'interdisciplinario', 'black', 'church', 'lanzado', 'braxton', 'shelley', 'grabada', 'video', 'formar', 'major', 'figures', 'comprende', 'datan', 'actualidad', 'destacados', 'compositores', 'mãºsicos', 'mediante', 'plataforma', 'aviary', 'acceder', 'solicitar', 'transcripciones', 'seleccione', 'premio', 'windham', 'campbell', 'reconocimiento', 'logros', 'literarios', 'excepcionales', 'establecido', 'regalo', 'donald', 'memoria', 'sandy', 'otorgado', 'escritores', 'ocho', 'windhamcampbell', 'exploran', 'personales', 'complejos', 'sexualidad', 'cultura', 'leer', 'formas', 'presente', 'futuro', 'michael', 'kelleher', 'puedo', 'esperar', 'hace', 'festival', 'literario', 'beneficiarios', 'representa', 'aumento', 'administrados', 'beinecke', 'rare', 'book', 'manuscript', 'library', 'generosos', 'prestigiosos', 'otorgan', 'anualmente', 'recibir', 'etapa', 'carrera', 'noventa', 'representan', 'recibido', 'destinatarios', 'nominados', 'confidencial', 'juzgados', 'saben', 'considerados', 'contacta', 'emocionado', 'eufemismo', 'enterarme', 'percival', 'everett', 'autor', 'libros', 'novela', 'finalista', 'pulitzer', 'ling', 'autora', 'severance', 'cuentos', 'bliss', 'montage', 'nombradas', 'notables', 'york', 'times', 'escritora', 'historiadora', 'londinense', 'susan', 'williams', 'examina', 'historias', 'ocultas', 'olvidadas', 'cuales', 'destruido', 'clasificado', 'redactado', 'documental', 'malice', 'cia', 'covert', 'recolonization', 'africa', 'mueve', 'congo', 'ghana', 'arrojar', 'deliberada', 'democracia', 'nuevos', 'independientes', 'tan', 'inesperada', 'rara', 'lucha', 'interrogar', 'buscar', 'verdad', 'profundamente', 'agradecido', 'seguir', 'adelante', 'renovada', 'fuerza', 'darran', 'anderson', 'ensayista', 'periodista', 'memorias', 'escribe', 'intersecciones', 'urbanismo', 'libro', 'inventario', 'cuenta', 'infancia', 'trabajadora', 'derry', 'irlanda', 'norte', 'apogeo', 'disturbios', 'obras', 'dramaturgo', 'dominique', 'morisseau', 'ciclo', 'aclamado', 'basa', 'ricas', 'literatura', 'activismo', 'afroamericano', 'crear', 'experiencias', 'inquebrantables', 'tremendamente', 'entretenidas', 'nominado', 'tony', 'aint', 'proud', 'life', 'temptations', 'beca', 'macarthur', 'sucede', 'placer', 'saber', 'voz', 'animan', 'continuar', 'artista', 'contando', 'vital', 'ayudan', 'abrir', 'camino', 'creatividad', 'prosperen', 'emocionante', 'inspirador', 'dramaturga', 'jasmine', 'leejones', 'ganadora', 'joven', 'escena', 'teatral', 'obra', 'debut', 'siete', 'matar', 'kylie', 'jenner', 'sigue', 'cleo', 'autoproclamada', 'activista', 'twitter', 'amiga', 'kara', 'negocian', 'identidades', 'enredadas', 'curious', 'racial', 'siglo', 'xviii', 'poeta', 'alexis', 'pauline', 'gumbs', 'educadora', 'utiliza', 'imaginar', 'viejas', 'narrativas', 'relacionarse', 'intelectual', 'imaginativo', 'negro', 'prosa', 'dub', 'finding', 'ceremony', 'undrowned', 'archive', 'spill', 'scenes', 'feminist', 'fugitivity', 'centrosur', 'alaska', 'dg', 'nanouk', 'okpik', 'abre', 'lectores', 'compleja', 'red', 'mito', 'corpse', 'whale', 'award', 'blood', 'snow', 'expoeta', 'laureada', 'joy', 'harjo', 'sorprendente', 'ceremonial', 'disruptivo', 'mil', 'marmotas', 'corriendo', 'tundra', 'nombrado', 'ganador', 'establecieron', 'pareja', 'discutido', 'destacar', 'concentrarse', 'independientemente', 'preocupaciones', 'financieras', 'inesperadamente', 'responsabilidad', 'realidad', 'compartido', 'theodore', 'kim', 'aplicadas', 'codirector', 'computadora', 'ex', 'pixar', 'veces', 'academia', 'habla', 'contrarrestar', 'prejuicios', 'raciales', 'peter', 'salovey', 'posgrado', 'lowe', 'phdï', 'solteras', 'orleans', 'katrina', 'zona', 'estaba', 'interesado', 'eventos', 'colectivos', 'impactan', 'disparidades', 'profesora', 'asociada', 'comportamiento', 'facultad', 'researchers', 'surveyed', 'women', 'next', 'years', 'noting', 'continued', 'negative', 'impact', 'hurricane', 'lives', 'overall', 'resilience', 'setback', 'many', 'earning', 'degrees', 'stable', 'housing', 'successfully', 'raising', 'children', 'despite', 'trauma', 'claro', 'iba', 'afectar', 'subpoblaciones', 'nuestra', 'muestra', 'experimentar', 'racismo', 'solteros', 'covid', 'casos', 'graves', 'impactos', 'destacaron', 'ãºnica', 'estudiar', 'vulnerable', 'sobrevivientes', 'experimentado', 'otro', 'colectivo', 'aproximadamente', 'febrero', 'meghan', 'zacher', 'brown', 'ethan', 'raker', 'columbia', 'compararon', 'impacto', 'mental', 'sorprendieron', 'ciento', 'experimentaron', 'porcentaje', 'exacto', 'esos', 'mitad', 'encuestados', 'experimentaba', 'angustia', 'tercio', 'mismos', 'peores', 'desastres', 'nacionales', 'diferencias', 'experiencia', 'corto', 'estuvo', 'limitado', 'dice', 'significa', 'resto', 'canalizar', 'hacia', 'costa', 'golfo', 'generalizada', 'muerte', 'duraron', 'combinada', 'condujo', 'ofrece', 'general', 'previo', 'largo', 'plazo', 'debemos', 'olvidar', 'hecho', 'muertes', 'hayan', 'disminuido', 'sigan', 'luchando', 'traumas', 'correr', 'adversidad', 'normalmente', 'habitãºa', 'desgaste', 'arreglan', 'crecen', 'aprenden', 'vulnerables', 'clave', 'surgir', 'brotes', 'tiroteos', 'masivos', 'incendios', 'fatales', 'accidentes', 'mãºltiples', 'estudio', 'conocimientos', 'respaldar', 'modificar', 'actual', 'manual', 'mentales', 'autorizado', 'tiene', 'luchas', 'enfrentar', 'experimentan', 'financiera', 'inestabilidad', 'vivienda', 'creen', 'facilitar', 'relacionados', 'accedan', 'coinvestigadores', 'continãºan', 'revisando', 'publicar', 'seguimiento', 'pronosticar', 'problema', 'califican', 'bob', 'atkinson', 'veterano', 'obtuvo', 'estrellas', 'bronce', 'encuentra', 'seleccionados', 'becarios', 'truman', 'eli', 'whitney', 'ayuda', 'tradicionales', 'universitarios', 'ganar', 'aspirantes', 'servicio', 'brinda', 'financiamiento', 'liderazgo', 'profesional', 'especiales', 'becas', 'gobierno', 'candidatos', 'colegios', 'universidades', 'base', 'potencial', 'confiamos', 'juntos', 'terry', 'babcocklumish', 'secretario', 'ejecutivo', 'becario', 'scholars', 'reflejan', 'solucionadores', 'problemas', 'innovadores', 'decididos', 'rehuyen', 'trumbull', 'originario', 'janesville', 'minnesota', 'graduarse', 'usaf', 'entrenamiento', 'guerra', 'especial', 'miembro', 'seleccionado', 'asignado', 'directamente', 'ranger', 'regiments', 'regimental', 'reconnaissance', 'company', 'despliegues', 'combate', 'irak', 'medalla', 'estrella', 'heroico', 'meritorio', 'quiere', 'dar', 'drogas', 'particularmente', 'mejorando', 'asistido', 'medicamentos', 'eliminando', 'pasante', 'oficina', 'cumplimiento', 'ley', 'oferta', 'planea', 'pãºblicas', 'derecho', 'estoy', 'emocionada', 'bobby', 'contenta', 'reconozca', 'historial', 'profundo', 'jill', 'directora', 'representante', 'tantos', 'inspiradores', 'dedican', 'carreras', 'sector', 'establecida', 'congreso', 'monumento', 'viviente', 'harry', 'unen', 'primeros', 'asesor', 'seguridad', 'jake', 'sullivan', 'jd', 'corte', 'suprema', 'neil', 'gorsuch', 'asesora', 'interna', 'casa', 'blanca', 'rice', 'fundadora', 'fair', 'fight', 'stacey', 'abrams', 'sabemos', 'materiales', 'defensa', 'revelado', 'suficientes', 'detalles', 'ni', 'desplegados', 'matt', 'erpelding', 'sff', 'servimos', 'nos', 'enfermamos', 'estuvimos', 'dolores', 'cabeza', 'sarpullidos', 'nosotros', 'estamos', 'enfermos', 'hemos', 'muerto', 'raras', 'senador', 'estadounidense', 'blumenthal', 'veteranos', 'sustancias', 'expuestos', 'blumental', 'pone', 'peligro', 'inaceptable', 'vidas', 'juego', 'error', 'corregirse', 'demasiado', 'litigio', 'presentado', 'hoy', 'resultado', 'numerosos', 'intentos', 'solicitud', 'foia', 'toxinas', 'documentadas', 'proporcionar', 'johns', 'hopkins', 'vitales', 'relacionadas', 'stronghold', 'incansablemente', 'cualquiera', 'actuar', 'rapidez', 'reciban', 'merecen', 'alison', 'weir', 'ejecutiva', 'cvlc', 'partes', 'demanda', 'insondable', 'continãºe', 'obstruyendo', 'afectando', 'servido', 'legal', 'lamentablemente', 'visto', 'otra', 'orgullosos', 'luchar', 'garantizar', 'tengan', 'ganaron', 'merecieron', 'presentaron', 'solicitudes', 'dod', 'registros', 'nada', 'desalentador', 'abandonado', 'propio', 'derek', 'nelson', 'legales', 'retener', 'moribundos', 'esperamos', 'paso', 'remediar', 'ese', 'brindarles', 'justicia', 'darwall', 'andrew', 'downey', 'orrick', 'artes', 'guggenheim', 'creada', 'simon', 'olga', 'hijo', 'john', 'honra', 'busca', 'campo', 'arte', 'subvenciones', 'libertad', 'deseen']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spanish_vocabulary, counts = find_vocabulary_count (all_words_spanish)\n",
    "print (spanish_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "178e625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8bd085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11442e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6d131e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "\n",
    "def converter_en (row):\n",
    "    bow = []\n",
    "    for w in english_vocabulary:\n",
    "        #print (w)\n",
    "        if w in row:\n",
    "            bow.append (1.0)\n",
    "        else:\n",
    "            bow.append (0.0)\n",
    "    return np.array (bow)\n",
    "\n",
    "\n",
    "def converter_es (row):\n",
    "    bow = []\n",
    "    for w in spanish_vocabulary:\n",
    "        #print (w)\n",
    "        if w in row:\n",
    "            bow.append (1.0)\n",
    "        else:\n",
    "            bow.append (0.0)\n",
    "    return np.array (bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27111967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
      "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: converter_en, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['converter_en'] = df['cleaned_english'].apply( converter_en)\n",
    "print (df['converter_en'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b80f9551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
      "1    [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "2    [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "3    [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
      "4    [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: converter_es, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['converter_es'] = df['cleaned_spanish'].apply( converter_es )\n",
    "print (df['converter_es'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50936b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English_tokens</th>\n",
       "      <th>Eng_lemmats</th>\n",
       "      <th>cleaned_english</th>\n",
       "      <th>cleaned_spanish</th>\n",
       "      <th>converter_en</th>\n",
       "      <th>converter_es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This weeks 2023 Spring Meetings of the World B...</td>\n",
       "      <td>Las Reuniones de Primavera de 2023 del Grupo d...</td>\n",
       "      <td>(This, weeks, 2023, Spring, Meetings, of, the,...</td>\n",
       "      <td>[this, week, 2023, Spring, Meetings, of, the, ...</td>\n",
       "      <td>[weeks, spring, meetings, world, bank, group, ...</td>\n",
       "      <td>[las, reuniones, de, primavera, de, del, grupo...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However many communities face social environme...</td>\n",
       "      <td>Sin embargo muchas comunidades enfrentan barre...</td>\n",
       "      <td>(However, many, communities, face, social, env...</td>\n",
       "      <td>[however, many, community, face, social, envir...</td>\n",
       "      <td>[however, many, communities, face, social, env...</td>\n",
       "      <td>[sin, embargo, muchas, comunidades, enfrentan,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can policymakers promote the conditions th...</td>\n",
       "      <td>Â¿CÃ³mo pueden los formuladores de polÃ­ticas ...</td>\n",
       "      <td>(How, can, policymakers, promote, the, conditi...</td>\n",
       "      <td>[how, can, policymaker, promote, the, conditio...</td>\n",
       "      <td>[policymakers, promote, conditions, overcome, ...</td>\n",
       "      <td>[pueden, los, formuladores, de, promover, las,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this episode of Voices in Development Kevin...</td>\n",
       "      <td>En este episodio de Voices in Development Kevi...</td>\n",
       "      <td>(In, this, episode, of, Voices, in, Developmen...</td>\n",
       "      <td>[in, this, episode, of, Voices, in, Developmen...</td>\n",
       "      <td>[episode, voices, development, kevin, donovan,...</td>\n",
       "      <td>[en, este, episodio, de, voices, development, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donovan has used macro and microeconomic model...</td>\n",
       "      <td>Donovan ha utilizado modelos macro y microecon...</td>\n",
       "      <td>(Donovan, has, used, macro, and, microeconomic...</td>\n",
       "      <td>[Donovan, have, use, macro, and, microeconomic...</td>\n",
       "      <td>[donovan, used, macro, microeconomic, models, ...</td>\n",
       "      <td>[donovan, ha, utilizado, modelos, macro, para,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0  This weeks 2023 Spring Meetings of the World B...   \n",
       "1  However many communities face social environme...   \n",
       "2  How can policymakers promote the conditions th...   \n",
       "3  In this episode of Voices in Development Kevin...   \n",
       "4  Donovan has used macro and microeconomic model...   \n",
       "\n",
       "                                             Spanish  \\\n",
       "0  Las Reuniones de Primavera de 2023 del Grupo d...   \n",
       "1  Sin embargo muchas comunidades enfrentan barre...   \n",
       "2  Â¿CÃ³mo pueden los formuladores de polÃ­ticas ...   \n",
       "3  En este episodio de Voices in Development Kevi...   \n",
       "4  Donovan ha utilizado modelos macro y microecon...   \n",
       "\n",
       "                                      English_tokens  \\\n",
       "0  (This, weeks, 2023, Spring, Meetings, of, the,...   \n",
       "1  (However, many, communities, face, social, env...   \n",
       "2  (How, can, policymakers, promote, the, conditi...   \n",
       "3  (In, this, episode, of, Voices, in, Developmen...   \n",
       "4  (Donovan, has, used, macro, and, microeconomic...   \n",
       "\n",
       "                                         Eng_lemmats  \\\n",
       "0  [this, week, 2023, Spring, Meetings, of, the, ...   \n",
       "1  [however, many, community, face, social, envir...   \n",
       "2  [how, can, policymaker, promote, the, conditio...   \n",
       "3  [in, this, episode, of, Voices, in, Developmen...   \n",
       "4  [Donovan, have, use, macro, and, microeconomic...   \n",
       "\n",
       "                                     cleaned_english  \\\n",
       "0  [weeks, spring, meetings, world, bank, group, ...   \n",
       "1  [however, many, communities, face, social, env...   \n",
       "2  [policymakers, promote, conditions, overcome, ...   \n",
       "3  [episode, voices, development, kevin, donovan,...   \n",
       "4  [donovan, used, macro, microeconomic, models, ...   \n",
       "\n",
       "                                     cleaned_spanish  \\\n",
       "0  [las, reuniones, de, primavera, de, del, grupo...   \n",
       "1  [sin, embargo, muchas, comunidades, enfrentan,...   \n",
       "2  [pueden, los, formuladores, de, promover, las,...   \n",
       "3  [en, este, episodio, de, voices, development, ...   \n",
       "4  [donovan, ha, utilizado, modelos, macro, para,...   \n",
       "\n",
       "                                        converter_en  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                        converter_es  \n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "1  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "2  [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "3  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "4  [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "236d15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_df, trg_df):\n",
    "        self.src_df = src_df\n",
    "        self.trg_df = trg_df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src_df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        src_sentence = self.src_df.iat[idx]\n",
    "        trg_sentence = self.trg_df.iat[idx]\n",
    "        \n",
    "\n",
    "        \n",
    "        return torch.tensor(src_sentence), torch.tensor(trg_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ddc0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(df['converter_en'], df['converter_es'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f51de45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "valid_ratio = 0.1\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6321c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train samples :  104\n",
      "num of test samples :  13\n",
      "num of valid samples :  13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = math.floor(dataset_size * train_ratio)\n",
    "test_size = math.floor(dataset_size * test_ratio)\n",
    "valid_size = dataset_size - train_size - test_size\n",
    "\n",
    "print (\"num of train samples : \", train_size)\n",
    "print (\"num of test samples : \", test_size)\n",
    "print (\"num of valid samples : \", valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e259e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(dataset_size))\n",
    "random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6c15f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 68, 20, 3, 50, 15, 16, 127, 121, 74, 109, 89, 67, 11, 102, 34, 4, 114, 100, 104, 80, 55, 14, 21, 105, 115, 37, 1, 57, 126, 22, 62, 59, 103, 27, 17, 75, 2, 65, 101, 93, 123, 82, 36, 24, 129, 63, 99, 76, 26, 0, 41, 32, 56, 8, 120, 45, 47, 88, 60, 6, 110, 28, 128, 116, 25, 31, 18, 125, 30, 83, 9, 40, 23, 7, 44, 85, 51, 48, 91, 118, 49, 70, 77, 92, 64, 117, 46, 52, 39, 35, 98, 97, 58, 19, 112, 54, 87, 96, 124, 106, 111, 71, 53]\n",
      "[66, 72, 5, 86, 122, 79, 10, 43, 94, 107, 108, 42, 81]\n",
      "[69, 38, 13, 12, 33, 73, 78, 84, 61, 95, 119, 90, 113]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:train_size+test_size]\n",
    "valid_indices = indices[train_size+test_size:]\n",
    "print (train_indices)\n",
    "print (test_indices)\n",
    "print (valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c55bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "valid_dataset = Subset(dataset, valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb351982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c87b39ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 1., 1., 1.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    # Process the batch\n",
    "    print (\"English inputs : \", inputs)\n",
    "    print (\"Spanish outputs : \", targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74348018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    # Process the batch\n",
    "    print (\"English inputs : \", inputs)\n",
    "    print (\"Spanish outputs : \", targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05b96710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "English inputs :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "Spanish outputs :  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "    # Process the batch\n",
    "    print (\"English inputs : \", inputs)\n",
    "    print (\"Spanish outputs : \", targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
